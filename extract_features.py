import os
import numpy as np
import torch
from PIL import Image
from tqdm import tqdm
import pickle
import open_clip

class ImageFeatureExtractor:
    """
    ä½¿ç”¨ BiomedCLIP æå–ä¹³æˆ¿ X å…‰å½±åƒçš„ç‰¹å¾µå‘é‡
    æ”¯æ´å€‹åˆ¥å½±åƒå’Œæ•´é«”å¹³å‡ç‰¹å¾µ
    """
    
    def __init__(self, model_name="hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224"):
        """åˆå§‹åŒ–æ¨¡å‹"""
        print("ğŸ”„ è¼‰å…¥ BiomedCLIP æ¨¡å‹...")
        self.device = torch.device("cpu")
        
        self.model, self.preprocess_train, self.preprocess_val = open_clip.create_model_and_transforms(model_name)
        self.tokenizer = open_clip.get_tokenizer(model_name)
        
        self.model.to(self.device)
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ (device: {self.device})")
    
    def extract_single_image(self, image_array):
        """æå–å–®å¼µå½±åƒçš„ç‰¹å¾µå‘é‡"""
        if len(image_array.shape) == 3:
            image_array = image_array.squeeze()
        
        image_array = image_array.astype(np.uint8)
        image_pil = Image.fromarray(image_array).convert('RGB')
        
        image_tensor = self.preprocess_val(image_pil).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            image_features = self.model.encode_image(image_tensor)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
        
        return image_features.cpu().numpy().squeeze()
    
    def extract_case_features(self, case_dir):
        """
        æå–ä¸€å€‹æ¡ˆä¾‹çš„æ‰€æœ‰å½±åƒç‰¹å¾µ
        
        Returns:
            features_dict: {
                'RCC': feature,
                'LCC': feature,
                'RMLO': feature,
                'LMLO': feature,
                'avg_all': 4å¼µå¹³å‡,
                'avg_right': RCC+RMLOå¹³å‡,
                'avg_left': LCC+LMLOå¹³å‡
            }
        """
        # å®šç¾©å½±åƒåç¨±å°æ‡‰
        view_mapping = {
            'I0000000.npy': 'RCC',   # Right CC
            'I0000001.npy': 'LCC',   # Left CC
            'I0000002.npy': 'RMLO',  # Right MLO
            'I0000003.npy': 'LMLO'   # Left MLO
        }
        
        features = {}
        
        for fname, view_name in view_mapping.items():
            file_path = os.path.join(case_dir, fname)
            
            if not os.path.exists(file_path):
                continue
            
            try:
                image_array = np.load(file_path)
                feature = self.extract_single_image(image_array)
                features[view_name] = feature
            except Exception as e:
                print(f"âš ï¸  è™•ç† {file_path} æ™‚å‡ºéŒ¯: {str(e)}")
                continue
        
        if len(features) == 0:
            raise ValueError(f"æ¡ˆä¾‹ {case_dir} æ²’æœ‰æœ‰æ•ˆçš„å½±åƒ!")
        
        # è¨ˆç®—ä¸åŒçµ„åˆçš„å¹³å‡ç‰¹å¾µ
        result = features.copy()
        
        # å…¨éƒ¨å¹³å‡
        all_features = list(features.values())
        result['avg_all'] = np.mean(all_features, axis=0)
        result['avg_all'] = result['avg_all'] / np.linalg.norm(result['avg_all'])
        
        # å³ä¹³å¹³å‡ (RCC + RMLO)
        if 'RCC' in features and 'RMLO' in features:
            result['avg_right'] = np.mean([features['RCC'], features['RMLO']], axis=0)
            result['avg_right'] = result['avg_right'] / np.linalg.norm(result['avg_right'])
        
        # å·¦ä¹³å¹³å‡ (LCC + LMLO)
        if 'LCC' in features and 'LMLO' in features:
            result['avg_left'] = np.mean([features['LCC'], features['LMLO']], axis=0)
            result['avg_left'] = result['avg_left'] / np.linalg.norm(result['avg_left'])
        
        return result
    
    def batch_extract_all_cases(self, preprocessed_dir='preprocessed_images/', 
                                output_file='mammography_features.pkl'):
        """æ‰¹æ¬¡è™•ç†æ‰€æœ‰æ¡ˆä¾‹"""
        features_dict = {}
        child_dirs = ['20230721_1st', '20230728_2nd', '20230804_3rd']
        
        print("\nğŸš€ é–‹å§‹æ‰¹æ¬¡æå–ç‰¹å¾µ...")
        
        total_success = 0
        total_failed = 0
        
        for child in child_dirs:
            child_path = os.path.join(preprocessed_dir, child)
            
            if not os.path.exists(child_path):
                print(f"âš ï¸  æ‰¾ä¸åˆ°è³‡æ–™å¤¾: {child_path}")
                continue
            
            cases = sorted([c for c in os.listdir(child_path) if os.path.isdir(os.path.join(child_path, c))])
            
            for case in tqdm(cases, desc=f"æå– {child} ç‰¹å¾µ"):
                case_dir = os.path.join(child_path, case)
                
                try:
                    # æå–ç‰¹å¾µï¼ˆåŒ…å«å€‹åˆ¥å’Œå¹³å‡ï¼‰
                    case_features = self.extract_case_features(case_dir)
                    
                    # å„²å­˜
                    features_dict[case] = {
                        'features': case_features,
                        'source_dir': child,
                        'num_views': len([k for k in case_features.keys() if k in ['RCC', 'LCC', 'RMLO', 'LMLO']])
                    }
                    
                    total_success += 1
                    
                except Exception as e:
                    print(f"âŒ æå– {case} ç‰¹å¾µå¤±æ•—: {str(e)}")
                    total_failed += 1
        
        # å„²å­˜ç‰¹å¾µ
        print(f"\nğŸ’¾ å„²å­˜ç‰¹å¾µåˆ° {output_file}...")
        with open(output_file, 'wb') as f:
            pickle.dump(features_dict, f)
        
        print(f"\n{'='*60}")
        print(f"âœ… å®Œæˆï¼")
        print(f"æˆåŠŸ: {total_success} å€‹æ¡ˆä¾‹")
        print(f"å¤±æ•—: {total_failed} å€‹æ¡ˆä¾‹")
        print(f"{'='*60}")
        
        return features_dict


# ==================== ä½¿ç”¨ç¯„ä¾‹ ====================

if __name__ == "__main__":
    # 1. åˆå§‹åŒ–ç‰¹å¾µæå–å™¨
    extractor = ImageFeatureExtractor()
    
    # 2. æ‰¹æ¬¡æå–æ‰€æœ‰æ¡ˆä¾‹çš„ç‰¹å¾µ
    features_dict = extractor.batch_extract_all_cases(
        preprocessed_dir='preprocessed_images/',
        output_file='mammography_features.pkl'
    )
    
    # 3. æŸ¥çœ‹çµæœ
    print("\n" + "="*60)
    print("ğŸ“Š ç‰¹å¾µæå–çµ±è¨ˆ:")
    print(f"ç¸½æ¡ˆä¾‹æ•¸: {len(features_dict)}")
    
    if len(features_dict) > 0:
        first_case_id = list(features_dict.keys())[0]
        first_case_data = features_dict[first_case_id]
        first_features = first_case_data['features']
        
        print(f"\nç¯„ä¾‹æ¡ˆä¾‹: {first_case_id}")
        print(f"å½±åƒæ•¸é‡: {first_case_data['num_views']}")
        print(f"\nå¯ç”¨ç‰¹å¾µé¡å‹:")
        for key in first_features.keys():
            print(f"  - {key}: {first_features[key].shape}")
        
        print(f"\nç‰¹å¾µå‘é‡ç¯„ä¾‹ (avg_all å‰10ç¶­):")
        print(f"  {first_features['avg_all'][:10]}")
        
        # çµ±è¨ˆ
        from collections import Counter
        source_counter = Counter([info['source_dir'] for info in features_dict.values()])
        print(f"\nå„æ™‚é–“é»æ¡ˆä¾‹æ•¸:")
        for source, count in sorted(source_counter.items()):
            print(f"  {source}: {count} å€‹æ¡ˆä¾‹")
    
    print("="*60)