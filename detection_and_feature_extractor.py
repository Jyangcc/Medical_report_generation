import os
import numpy as np
import torch
from PIL import Image
from tqdm import tqdm
import pickle
import open_clip
from typing import List, Dict, Any
import tempfile # è™•ç†æš«å­˜æª”æ¡ˆ


from inference_sdk import InferenceHTTPClient

class LesionDetector:
    """
    [V3 ç‰ˆ - API å‘¼å«]
    ä½¿ç”¨ Roboflow HTTP API é€²è¡Œç—…ç¶æª¢æ¸¬
    """
    def __init__(self):
        """
        åˆå§‹åŒ– Roboflow API å®¢æˆ¶ç«¯
        """
        print(f"ğŸ”„ åˆå§‹åŒ– Roboflow API å®¢æˆ¶ç«¯...")
        
        # ï¼ï¼ï¼å¾ç’°å¢ƒè®Šæ•¸è®€å– API Keyï¼ï¼ï¼
        # çµ•å°ä¸è¦æŠŠ Key å¯«æ­»åœ¨é€™è£¡
        self.api_key = os.environ.get("ROBOFLOW_API_KEY")
        if not self.api_key:
            print("="*80)
            print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° ROBOFLOW_API_KEY ç’°å¢ƒè®Šæ•¸")
            print("è«‹å…ˆè¨­å®š: export ROBOFLOW_API_KEY='your_roboflow_key_here'")
            print("="*80)
            raise ValueError("ROBOFLOW_API_KEY not set")
            
        self.client = InferenceHTTPClient(
            api_url="https://serverless.roboflow.com",
            api_key=self.api_key
        )
        
        # é€™æ˜¯ä½ æ‰¾åˆ°çš„è«–æ–‡æ‰€ä½¿ç”¨çš„æ¨¡å‹ ID
        self.model_id = "breast-cancer-jtuaz/1"
        
        print(f"âœ… Roboflow API å®¢æˆ¶ç«¯åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {self.model_id})")

    def detect(self, image_pil: Image.Image) -> List[Dict[str, Any]]:
        """
        å°å–®å¼µ PIL å½±åƒé€²è¡Œç—…ç¶æª¢æ¸¬ (é€é API)
        
        Returns:
            lesions: æª¢æ¸¬åˆ°çš„ç—…ç¶åˆ—è¡¨ï¼ŒåŒ…å« 'bbox' (x1, y1, x2, y2) å’Œ 'conf'
        """
        
        # 1. å°‡ PIL å½±åƒå„²å­˜åˆ°ä¸€å€‹æš«å­˜æª”æ¡ˆ
        # InferenceHTTPClient.infer() éœ€è¦ä¸€å€‹æª”æ¡ˆè·¯å¾‘
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=True) as temp_file:
            # ç¢ºä¿å½±åƒæ˜¯ RGB (å¦‚æœå®ƒæ˜¯ç°éš 'L' çš„è©±)
            image_rgb = image_pil.convert("RGB")
            image_rgb.save(temp_file.name, format="JPEG")
            
            # 2. å‘¼å« Roboflow API
            try:
                result = self.client.infer(temp_file.name, model_id=self.model_id)
            except Exception as e:
                print(f"âŒ Roboflow API å‘¼å«å¤±æ•—: {e}")
                return [] # è¿”å›ç©ºåˆ—è¡¨

        # 3. è§£æ API å›å‚³çš„ JSON çµæœ
        lesions = []
        img_w, img_h = image_pil.size # å–å¾—åŸå§‹å½±åƒå°ºå¯¸

        for pred in result.get('predictions', []):
            # ... (å–å¾— x_center, y_center, width, height çš„ä»£ç¢¼ä¸è®Š) ...
            x_center = pred['x']
            y_center = pred['y']
            width = pred['width']
            height = pred['height']
            confidence = pred['confidence']

            x1 = int(x_center - width / 2)
            y1 = int(y_center - height / 2)
            x2 = int(x_center + width / 2)
            y2 = int(y_center + height / 2)

            # ï¼ï¼ï¼æ–°å¢ï¼šè¨ˆç®—ç›¸å°ä½ç½® (0.0 ~ 1.0)ï¼ï¼ï¼
            rel_x = x_center / img_w
            rel_y = y_center / img_h

            lesions.append({
                'bbox': [x1, y1, x2, y2],
                'conf': confidence,
                'rel_center': (rel_x, rel_y) # <--- åŠ å…¥é€™å€‹æ–°è³‡è¨Š
            })

        return lesions

class ImageFeatureExtractor:
    """
    [V3 ç‰ˆ - API æª¢æ¸¬]
    ä½¿ç”¨ BiomedCLIP æå–ã€Œå…¨åŸŸç‰¹å¾µã€å’Œã€Œå±€éƒ¨ç—…ç¶ç‰¹å¾µã€
    """
    
    def __init__(self, 
                 clip_model_name="hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224"):
        """åˆå§‹åŒ–æ¨¡å‹"""
        
        # 1. ï¼ï¼ï¼åˆå§‹åŒ– API ç‰ˆæœ¬çš„ç—…ç¶æª¢æ¸¬å™¨ï¼ï¼ï¼
        #    (ä¸å†éœ€è¦ detector_model_path)
        self.detector = LesionDetector()
        
        # 2. åˆå§‹åŒ– CLIP ç‰¹å¾µæå–å™¨ (é€™éƒ¨åˆ†ä¸è®Š)
        print("ğŸ”„ è¼‰å…¥ BiomedCLIP æ¨¡å‹...")
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        self.clip_model, _, self.clip_preprocess = open_clip.create_model_and_transforms(clip_model_name)
        
        self.clip_model.to(self.device)
        self.clip_model.eval()
        
        print(f"âœ… BiomedCLIP æ¨¡å‹è¼‰å…¥å®Œæˆ (device: {self.device})")
    
    def extract_clip_feature(self, image_pil: Image.Image) -> np.ndarray:
        """æå–å–®å¼µ PIL å½±åƒ (å…¨åœ–æˆ–è£å‰ª) çš„ç‰¹å¾µå‘é‡ (ä¸è®Š)"""
        
        image_tensor = self.clip_preprocess(image_pil).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            image_features = self.clip_model.encode_image(image_tensor)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
        
        return image_features.cpu().numpy().squeeze()
    
    def _convert_npy_to_pil(self, image_array: np.ndarray) -> Image.Image:
        """å°‡ NPY é™£åˆ—è½‰æ›ç‚ºé©åˆæª¢æ¸¬å’Œæå–çš„ PIL å½±åƒ (ä¸è®Š)"""
        if len(image_array.shape) == 3:
            image_array = image_array.squeeze()
        
        if image_array.dtype != np.uint8:
            image_array = (image_array / image_array.max() * 255).astype(np.uint8)
        
        # è½‰æ›ç‚º PIL (YOLO éœ€è¦ RGB, CLIP ä¹Ÿéœ€è¦ RGB)
        return Image.fromarray(image_array).convert('RGB')

    
    def extract_case_features(self, case_dir: str) -> Dict[str, Any]:
        """
        [V3 ç‰ˆ] æå–ä¸€å€‹æ¡ˆä¾‹çš„æ‰€æœ‰å½±åƒç‰¹å¾µ (å…¨åŸŸ + å±€éƒ¨) (ä¸è®Š)
        """
        view_mapping = {
            'I0000000.npy': 'RCC',   # Right CC
            'I0000001.npy': 'LCC',   # Left CC
            'I0000002.npy': 'RMLO',  # Right MLO
            'I0000003.npy': 'LMLO'   # Left MLO
        }
        
        features = {}
        global_features_cache = {} # ç”¨æ–¼è¨ˆç®—å¹³å‡
        
        for fname, view_name in view_mapping.items():
            file_path = os.path.join(case_dir, fname)
            
            if not os.path.exists(file_path):
                continue
            
            try:
                # 1. è¼‰å…¥ä¸¦è½‰æ›å½±åƒ
                image_array = np.load(file_path)
                image_pil = self._convert_npy_to_pil(image_array)
                
                # 2. æå–å…¨åŸŸç‰¹å¾µ (ç”¨æ–¼å¯†åº¦ RAG)
                global_feature = self.extract_clip_feature(image_pil)
                global_features_cache[view_name] = global_feature
                
                # 3. æª¢æ¸¬ç—…ç¶ (!!!ç¾åœ¨æœƒå‘¼å« API!!!)
                detected_lesions = self.detector.detect(image_pil)
                
                processed_lesions = []
                # 4. æå–æ¯å€‹ç—…ç¶çš„å±€éƒ¨ç‰¹å¾µ (ç”¨æ–¼ç—…ç¶ RAG)
                for lesion in detected_lesions:
                    bbox = lesion['bbox']
                    
                    # è£å‰ªç—…ç¶å€åŸŸ
                    img_crop_pil = image_pil.crop((bbox[0], bbox[1], bbox[2], bbox[3]))
                    
                    # æå– ROI ç‰¹å¾µ
                    roi_feature = self.extract_clip_feature(img_crop_pil)
                    
                    processed_lesions.append({
                        'bbox': bbox, # å·²ç¶“æ˜¯ list
                        'conf': lesion['conf'],
                        'roi_feature': roi_feature
                    })
                
                # 5. å„²å­˜è©²å½±åƒçš„æ‰€æœ‰è³‡è¨Š
                features[view_name] = {
                    'global_feature': global_feature,
                    'lesions': processed_lesions
                }

            except Exception as e:
                print(f"âš ï¸  è™•ç† {file_path} æ™‚å‡ºéŒ¯: {str(e)}")
                continue
        
        if len(features) == 0:
            raise ValueError(f"æ¡ˆä¾‹ {case_dir} æ²’æœ‰æœ‰æ•ˆçš„å½±åƒ!")
        
        # 6. è¨ˆç®—ä¸åŒçµ„åˆçš„å¹³å‡ã€Œå…¨åŸŸã€ç‰¹å¾µ (ä¸è®Š)
        result = features.copy()
        
        all_global = list(global_features_cache.values())
        if all_global:
            avg_all = np.mean(all_global, axis=0)
            result['avg_all_global'] = avg_all / np.linalg.norm(avg_all)
        
        if 'RCC' in global_features_cache and 'RMLO' in global_features_cache:
            avg_right = np.mean([global_features_cache['RCC'], global_features_cache['RMLO']], axis=0)
            result['avg_right_global'] = avg_right / np.linalg.norm(avg_right)
        
        if 'LCC' in global_features_cache and 'LMLO' in global_features_cache:
            avg_left = np.mean([global_features_cache['LCC'], global_features_cache['LMLO']], axis=0)
            result['avg_left_global'] = avg_left / np.linalg.norm(avg_left)
            
        return result
    
    # 
    # batch_extract_all_cases() (åœ¨ V2 ä¸­) ä¿æŒä¸è®Š
    #
    def batch_extract_all_cases(self, preprocessed_dir='preprocessed_images/', 
                                output_file='mammography_features_v2.pkl'):
        """[V3 ç‰ˆ] æ‰¹æ¬¡è™•ç†æ‰€æœ‰æ¡ˆä¾‹ (é‚è¼¯ä¸è®Š)"""
        features_dict = {}
        child_dirs = ['20230721_1st', '20230728_2nd', '20230804_3rd']
        
        print("\nğŸš€ é–‹å§‹ V3 æ‰¹æ¬¡æå–ç‰¹å¾µ (API æª¢æ¸¬ + å±€éƒ¨ç‰¹å¾µ)...")
        
        total_success = 0
        total_failed = 0
        
        for child in child_dirs:
            child_path = os.path.join(preprocessed_dir, child)
            
            if not os.path.exists(child_path):
                print(f"âš ï¸  æ‰¾ä¸åˆ°è³‡æ–™å¤¾: {child_path}")
                continue
            
            cases = sorted([c for c in os.listdir(child_path) if os.path.isdir(os.path.join(child_path, c))])
            
            # ï¼ï¼ï¼DEBUGGING: å…ˆåªè·‘ 5 å€‹æ¡ˆä¾‹æ¸¬è©¦ APIï¼ï¼ï¼
            # print("--- âš ï¸  è­¦å‘Š: æ­£åœ¨ä»¥ 5 å€‹æ¡ˆä¾‹é€²è¡Œ API æ¸¬è©¦ ---")
            # cases = cases[:5] 
            
            for case in tqdm(cases, desc=f"æå– {child} ç‰¹å¾µ"):
                case_dir = os.path.join(child_path, case)
                
                try:
                    case_features = self.extract_case_features(case_dir)
                    
                    # è¨ˆç®—é€™å€‹æ¡ˆä¾‹ç¸½å…±æ‰¾åˆ°å¤šå°‘ç—…ç¶
                    total_lesions = 0
                    for view in ['RCC', 'LCC', 'RMLO', 'LMLO']:
                        if view in case_features:
                            total_lesions += len(case_features[view]['lesions'])
                    
                    features_dict[case] = {
                        'features': case_features,
                        'source_dir': child,
                        'total_lesions_found': total_lesions
                    }
                    total_success += 1
                    
                except Exception as e:
                    print(f"âŒ æå– {case} ç‰¹å¾µå¤±æ•—: {str(e)}")
                    total_failed += 1
        
        # å„²å­˜ç‰¹å¾µ
        print(f"\nğŸ’¾ å„²å­˜ V2 ç‰¹å¾µåˆ° {output_file}...")
        with open(output_file, 'wb') as f:
            pickle.dump(features_dict, f)
        
        print(f"\n{'='*60}")
        print(f"âœ… V2 ç‰¹å¾µæå–å®Œæˆï¼")
        print(f"æˆåŠŸ: {total_success} å€‹æ¡ˆä¾‹")
        print(f"å¤±æ•—: {total_failed} å€‹æ¡ˆä¾‹")
        print(f"{'='*60}")
        
        return features_dict