import os
import numpy as np
import base64
import io
import re
import glob
from typing import List, Dict, Any, Optional
from PIL import Image
from anthropic import Anthropic

# å°å…¥å¿…è¦çš„æ¨¡çµ„
from detection_and_feature_extractor import LesionDetector

class MammographyNoRAGSystem:
    """
    [å°ç…§çµ„] ç„¡ RAG çš„ç´” VLM å ±å‘Šç”Ÿæˆç³»çµ±
    ç‰¹é»ï¼š
    1. ä¸è¼‰å…¥ FAISS ç´¢å¼•ã€‚
    2. ä¸é€²è¡Œå¯†åº¦æˆ–ç—…ç¶æª¢ç´¢ã€‚
    3. åƒ…ä¾è³´ VLM æœ¬èº«çš„çŸ¥è­˜å’Œæˆ‘å€‘æä¾›çš„å½±åƒ(å«ç—…ç¶è£å‰ª)ã€‚
    """
    def __init__(self):
        print("="*80)
        print("ğŸš€ åˆå§‹åŒ– No-RAG å°ç…§çµ„ç³»çµ±...")
        
        # 1. åˆå§‹åŒ– Anthropic API
        self.anthropic_api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not self.anthropic_api_key:
            raise ValueError("ANTHROPIC_API_KEY æœªè¨­å®š")
        self.client = Anthropic(api_key=self.anthropic_api_key)
        
        # 2. åˆå§‹åŒ–ç—…ç¶æª¢æ¸¬å™¨ (API ç‰ˆæœ¬)
        # æˆ‘å€‘ä»ç„¶éœ€è¦å®ƒä¾†"çœ‹"åˆ°ç´°å¾®çš„ç—…ç¶ä¸¦è£å‰ªçµ¦ VLM
        self.detector = LesionDetector()
        
        print("âœ… No-RAG ç³»çµ±åˆå§‹åŒ–å®Œæˆ (åƒ…ä½¿ç”¨ VLM + æª¢æ¸¬å™¨)")

    def _image_to_base64(self, image_pil: Image.Image) -> str:
        """[V3 ä¿®æ­£ç‰ˆ] å°‡ PIL å½±åƒè½‰æ›ç‚º Base64 (ä½¿ç”¨ JPEG å£“ç¸®ä»¥ç¬¦åˆ 5MB é™åˆ¶)"""
        byte_arr = io.BytesIO()
        image_pil = image_pil.convert('RGB')
        # ä½¿ç”¨ JPEG ä¸¦è¨­å®šå“è³ªç‚º 90ï¼Œå¹³è¡¡ç•«è³ªèˆ‡æª”æ¡ˆå¤§å°
        image_pil.save(byte_arr, format='JPEG', quality=90)
        encoded_string = base64.b64encode(byte_arr.getvalue()).decode('utf-8')
        
        # å¦‚æœé‚„æ˜¯å¤ªå¤§ (è¶…é ~5MB)ï¼Œé™ä½å“è³ªé‡è©¦
        if len(encoded_string) * 0.75 > 5 * 1024 * 1024:
             byte_arr = io.BytesIO()
             image_pil.save(byte_arr, format='JPEG', quality=75)
             encoded_string = base64.b64encode(byte_arr.getvalue()).decode('utf-8')
             
        return encoded_string

    def _load_case_images(self, case_id: str) -> Dict[str, Image.Image]:
        """æœå°‹ä¸¦è¼‰å…¥æ¡ˆä¾‹çš„ 4 å¼µåŸå§‹å½±åƒ (å›å‚³ PIL æ ¼å¼)"""
        # ä½¿ç”¨ glob æ‰¾å‡ºæ¡ˆä¾‹æ‰€åœ¨çš„å­ç›®éŒ„ (ä¾‹å¦‚ 20230721_1st)
        case_paths = glob.glob(os.path.join('preprocessed_images', '*', case_id))
        if not case_paths:
            print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æ¡ˆä¾‹ {case_id} çš„å½±åƒè³‡æ–™å¤¾")
            return {}
        
        case_dir = case_paths[0]
        image_views = {
            'RCC': 'I0000000.npy', 'LCC': 'I0000001.npy',
            'RMLO': 'I0000002.npy', 'LMLO': 'I0000003.npy'
        }
        
        pil_images = {}
        for view_name, file_name in image_views.items():
            file_path = os.path.join(case_dir, file_name)
            if os.path.exists(file_path):
                try:
                    image_array = np.load(file_path)
                    # è½‰æ›ç‚º PIL RGB (VLM éœ€è¦)
                    if len(image_array.shape) == 3:
                        image_array = image_array.squeeze()
                    if image_array.dtype != np.uint8:
                        image_array = (image_array / image_array.max() * 255).astype(np.uint8)
                    pil_images[view_name] = Image.fromarray(image_array).convert('RGB')
                except Exception as e:
                    print(f"âš ï¸  è®€å–å½±åƒ {file_path} å¤±æ•—: {str(e)}")
        return pil_images

    def _generate_no_rag_prompt(self, case_id: str, detected_lesions_count: int) -> str:
        """ç”Ÿæˆä¸åŒ…å«ä»»ä½•åƒè€ƒæ¡ˆä¾‹çš„ Prompt"""
        
        lesion_instruction = ""
        if detected_lesions_count > 0:
            lesion_instruction = f"My detector has identified {detected_lesions_count} potential lesion(s), shown in the 'Cropped Lesion' images. Please carefully evaluate these regions."
        else:
            lesion_instruction = "My detector did NOT find any obvious lesions. Please double-check the full images to confirm if it's truly negative."

        return f"""You are an expert radiologist. Analyze the provided mammography images for patient {case_id}.

**CRITICAL INSTRUCTIONS (NO-RAG MODE):**
1.  **SOLE SOURCE OF TRUTH:** You have NO external reference cases. You must rely **ONLY** on your medical knowledge to analyze the provided images (Full Views + Cropped Lesions).
2.  **DETECTED LESIONS:** {lesion_instruction}
3.  **REPORTING:** If you see a suspicious finding, describe its location, size, and shape, and assign BI-RADS 0. If the breasts are clear, assign BI-RADS 1.

**MANDATORY FORMAT:**

<REPORT_TEXT>
**Bilateral screening mammograms**

1. [Describe breast density]
2. [Describe any findings or state 'No suspicious masses, calcifications, or architectural distortion.']
</REPORT_TEXT>

<BI_RADS_CATEGORY>
[Single digit ONLY: 0, 1, 2...]
</BI_RADS_CATEGORY>

<COMPARISON>
Not specified/Unknown
</COMPARISON>
"""

    def run_no_rag_evaluation(self, query_case_id: str) -> str:
        """
        åŸ·è¡Œ No-RAG è©•ä¼°æµç¨‹
        """
        print(f"ğŸš€ [No-RAG] é–‹å§‹è©•ä¼°: {query_case_id}")
        
        # 1. è¼‰å…¥å½±åƒ
        full_pil_images = self._load_case_images(query_case_id)
        if not full_pil_images:
            return "Error: Images not found"

        # 2. æº–å‚™å¤šæ¨¡æ…‹è¨Šæ¯ (å«å³æ™‚æª¢æ¸¬)
        content_list = []
        detected_lesions_count = 0
        
        for view in ['RCC', 'LCC', 'RMLO', 'LMLO']:
            if view in full_pil_images:
                pil_img = full_pil_images[view]
                
                # a. åŠ å…¥å…¨å¹…å½±åƒ (ä½¿ç”¨ä¿®æ­£å¾Œçš„ JPEG Base64)
                content_list.append({"type": "text", "text": f"--- Full-View Image: {view} ---"})
                content_list.append({
                    "type": "image",
                    "source": {"type": "base64", "media_type": "image/jpeg", "data": self._image_to_base64(pil_img)}
                })
                
                # b. å³æ™‚æª¢æ¸¬ä¸¦åŠ å…¥è£å‰ªå½±åƒ
                # æ³¨æ„ï¼šé€™è£¡æœƒå‘¼å« Roboflow APIï¼Œæ‰€ä»¥é‚„æ˜¯éœ€è¦æ™‚é–“å’Œæˆæœ¬
                try:
                    lesions = self.detector.detect(pil_img)
                    for lesion in lesions:
                        detected_lesions_count += 1
                        bbox = lesion['bbox']
                        cropped_pil = pil_img.crop((bbox[0], bbox[1], bbox[2], bbox[3]))
                        
                        content_list.append({"type": "text", "text": f"--- Cropped Lesion #{detected_lesions_count} (from {view}, Conf: {lesion['conf']:.2f}) ---"})
                        content_list.append({
                            "type": "image",
                            "source": {"type": "base64", "media_type": "image/jpeg", "data": self._image_to_base64(cropped_pil)}
                        })
                except Exception as e:
                    print(f"âš ï¸  {view} æª¢æ¸¬å¤±æ•—: {e}")

        print(f"âœ… å½±åƒæº–å‚™å®Œæˆ (æª¢æ¸¬åˆ° {detected_lesions_count} å€‹ç—…ç¶)")

        # 3. å»ºæ§‹ Prompt
        system_prompt = self._generate_no_rag_prompt(query_case_id, detected_lesions_count)
        content_list.append({"type": "text", "text": "Generate the report now based solely on these images."})

        # 4. å‘¼å« Claude API
        print(f"ğŸ¤– å‘¼å« Claude API (No-RAG)...")
        try:
            message = self.client.messages.create(
                model="claude-sonnet-4-5-20250929", 
                max_tokens=1024, # No-RAG å ±å‘Šé€šå¸¸è¼ƒçŸ­
                temperature=0.1,
                system=system_prompt,
                messages=[{"role": "user", "content": content_list}]
            )
            return message.content[0].text
        except Exception as e:
            print(f"âŒ API å‘¼å«å¤±æ•—: {e}")
            raise