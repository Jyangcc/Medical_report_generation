import os
import numpy as np
import pickle
import faiss
import base64
from typing import List, Dict, Any
from PIL import Image
import re
import io

# å°å…¥æˆ‘å€‘ç¾æœ‰çš„æ¨¡çµ„
from Get_Report import MammographyDataLoader, MammographyReport
from detection_and_feature_extractor import ImageFeatureExtractor # å°å…¥ V3 (API) ç‰ˆæœ¬çš„æå–å™¨
from anthropic import Anthropic

# ==============================================================================
# éšæ®µ 2.1: V2 æª¢ç´¢ç³»çµ± (FAISS ç´¢å¼•å®¢æˆ¶ç«¯)
# ==============================================================================

class MammographyRetrievalSystemV2:
    """
    [V2 ç‰ˆ]
    è¼‰å…¥ä¸¦ç®¡ç†æ‰€æœ‰ V2 ç´¢å¼• (å…¨åŸŸ + ç—…ç¶)
    """
    def __init__(self, features_v2_file='mammography_features_v2.pkl'):
        print("ğŸ”„ åˆå§‹åŒ– V2 æª¢ç´¢ç³»çµ±...")
        
        # 1. è¼‰å…¥ V2 ç‰¹å¾µ (æˆ‘å€‘éœ€è¦å®ƒä¾†è®€å–å½±åƒ)
        print(f"ğŸ”„ è¼‰å…¥ V2 ç‰¹å¾µè³‡æ–™: {features_v2_file}")
        with open(features_v2_file, 'rb') as f:
            self.features_dict_v2 = pickle.load(f)
        
        # 2. è¼‰å…¥å…¨åŸŸç´¢å¼•
        self.global_indices = {}
        self.global_maps = {}
        for feature_type in ['avg_all_global', 'avg_right_global', 'avg_left_global']:
            index_file = f"faiss_global_{feature_type}.index"
            map_file = f"faiss_global_{feature_type}_map.pkl"
            if os.path.exists(index_file) and os.path.exists(map_file):
                print(f"  - è¼‰å…¥å…¨åŸŸç´¢å¼•: {index_file}")
                self.global_indices[feature_type] = faiss.read_index(index_file)
                with open(map_file, 'rb') as f:
                    self.global_maps[feature_type] = pickle.load(f)
            else:
                print(f"âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ°å…¨åŸŸç´¢å¼• {index_file}ï¼Œå°‡ç„¡æ³•é€²è¡Œå¯†åº¦ RAG")
                
        # 3. è¼‰å…¥ç—…ç¶ (ROI) ç´¢å¼•
        self.lesion_index = None
        self.lesion_map = None
        lesion_index_file = "faiss_lesion_roi.index"
        lesion_map_file = "faiss_lesion_roi_map.pkl"
        if os.path.exists(lesion_index_file) and os.path.exists(lesion_map_file):
            print(f"  - è¼‰å…¥ç—…ç¶ç´¢å¼•: {lesion_index_file} (å…± {faiss.read_index(lesion_index_file).ntotal} å€‹ç—…ç¶)")
            self.lesion_index = faiss.read_index(lesion_index_file)
            with open(lesion_map_file, 'rb') as f:
                self.lesion_map = pickle.load(f)
        else:
            print("âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ°ç—…ç¶ç´¢å¼•ï¼Œå°‡ç„¡æ³•é€²è¡Œç—…ç¶ RAG")
        
        print("âœ… V2 æª¢ç´¢ç³»çµ±è¼‰å…¥å®Œæˆ")

    def search_global(self, query_feature: np.ndarray, k: int, feature_type: str = 'avg_all_global') -> List[Dict[str, Any]]:
        """
        æœå°‹ã€Œå…¨åŸŸã€ç´¢å¼• (ç”¨æ–¼å¯†åº¦/é¢¨æ ¼)
        """
        if feature_type not in self.global_indices:
            print(f"âŒ éŒ¯èª¤: å…¨åŸŸç´¢å¼• {feature_type} æœªè¼‰å…¥")
            return []
            
        index = self.global_indices[feature_type]
        id_map = self.global_maps[feature_type]
        
        # æº–å‚™æŸ¥è©¢å‘é‡
        query_feature = query_feature.astype('float32').reshape(1, -1)
        faiss.normalize_L2(query_feature) # ç¢ºä¿æ­£è¦åŒ–
        
        similarities, indices = index.search(query_feature, k)
        
        results = []
        for sim, idx in zip(similarities[0], indices[0]):
            if idx == -1: continue # FAISS å¯èƒ½è¿”å› -1
            results.append({
                'case_id': id_map[idx],
                'similarity': float(sim)
            })
        return results

    def search_lesion(self, query_roi_feature: np.ndarray, k: int) -> List[Dict[str, Any]]:
        """
        æœå°‹ã€Œç—…ç¶ã€ç´¢å¼• (ç”¨æ–¼ç—…ç¶æè¿°)
        """
        if self.lesion_index is None:
            print("âŒ éŒ¯èª¤: ç—…ç¶ç´¢å¼•æœªè¼‰å…¥")
            return []
        
        query_roi_feature = query_roi_feature.astype('float32').reshape(1, -1)
        faiss.normalize_L2(query_roi_feature)
        
        similarities, indices = self.lesion_index.search(query_roi_feature, k)
        
        results = []
        for sim, idx in zip(similarities[0], indices[0]):
            if idx == -1: continue
            # è¿”å›å„²å­˜åœ¨ map ä¸­çš„å®Œæ•´å…ƒæ•¸æ“š
            metadata = self.lesion_map[idx].copy() # è¤‡è£½ä¸€ä»½
            metadata['similarity'] = float(sim)
            results.append(metadata)
        return results

    def get_case_images_from_v2_features(self, case_id: str) -> Dict[str, Image.Image]:
        """
        è¼”åŠ©å‡½å¼ï¼šå¾ V2 ç‰¹å¾µåº«ä¸­è®€å–åŸå§‹å½±åƒ (NPY -> PIL)
        """
        case_data = self.features_dict_v2.get(case_id)
        if not case_data:
            print(f"âŒ éŒ¯èª¤: æ¡ˆä¾‹ {case_id} ä¸åœ¨ V2 ç‰¹å¾µåº«ä¸­")
            return {}
            
        source_dir = case_data['source_dir']
        base_dir = 'preprocessed_images'
        
        image_views = {
            'RCC': 'I0000000.npy', 'LCC': 'I0000001.npy',
            'RMLO': 'I0000002.npy', 'LMLO': 'I0000003.npy'
        }
        
        pil_images = {}
        for view_name, file_name in image_views.items():
            file_path = os.path.join(base_dir, source_dir, case_id, file_name)
            if os.path.exists(file_path):
                try:
                    image_array = np.load(file_path)
                    # è½‰æ›ç‚º PIL (éœ€è¦ RGB ä»¥ä¾¿ VLM è®€å–)
                    if len(image_array.shape) == 3:
                        image_array = image_array.squeeze()
                    if image_array.dtype != np.uint8:
                        image_array = (image_array / image_array.max() * 255).astype(np.uint8)
                    pil_images[view_name] = Image.fromarray(image_array).convert('RGB')
                except Exception as e:
                    print(f"âš ï¸  è®€å–å½±åƒ {file_path} å¤±æ•—: {str(e)}")
        return pil_images


# ==============================================================================
# éšæ®µ 2.2: V2 RAG ç³»çµ± (å¤šéšæ®µç”Ÿæˆ)
# ==============================================================================

class MammographyRAGSystemV2:
    """
    [V2 ç‰ˆ]
    çµåˆ V3 ç‰¹å¾µæå–å™¨ å’Œ V2 æª¢ç´¢ç³»çµ±ï¼ŒåŸ·è¡Œå¤šéšæ®µ RAG
    """
    def __init__(self, reports_dir='Kang_Ning_General_Hospital/'):
        print("="*80)
        print("ğŸš€ åˆå§‹åŒ– V2 RAG ç³»çµ± (å¤šéšæ®µç”Ÿæˆ)...")
        
        # 1. åˆå§‹åŒ– Anthropic API
        self.anthropic_api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not self.anthropic_api_key:
            raise ValueError("ANTHROPIC_API_KEY æœªè¨­å®š")
        self.client = Anthropic(api_key=self.anthropic_api_key)
        
        # 2. å¯¦ä¾‹åŒ– V3 ç‰¹å¾µæå–å™¨ (API ç‰ˆæœ¬)
        self.feature_extractor = ImageFeatureExtractor()
        
        # 3. å¯¦ä¾‹åŒ– V2 æª¢ç´¢ç³»çµ± (FAISS å®¢æˆ¶ç«¯)
        self.retrieval_system = MammographyRetrievalSystemV2()
        
        # 4. è¼‰å…¥å ±å‘Šè³‡æ–™åº« (ç”¨æ–¼ RAG æª¢ç´¢)
        print("ğŸ”„ è¼‰å…¥å ±å‘Šè³‡æ–™åº«...")
        self.report_loader = MammographyDataLoader(reports_dir)
        self.reports = self.report_loader.load_all_reports()
        self.reports_dict = {report.case_id: report for report in self.reports}
        print(f"âœ… å ±å‘Šè³‡æ–™åº«è¼‰å…¥å®Œæˆ (å…± {len(self.reports_dict)} ä»½å ±å‘Š)")
        
        print("âœ… V2 RAG ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼")

    def _image_to_base64(self, image_pil: Image.Image) -> str:
        """[V3 ä¿®æ­£ç‰ˆ] å°‡ PIL å½±åƒè½‰æ›ç‚º Base64 (ä½¿ç”¨ JPEG å£“ç¸®)"""
        byte_arr = io.BytesIO()
        
        # é—œéµä¿®æ”¹ï¼š
        # 1. ç¢ºä¿å½±åƒæ˜¯ RGB (JPEG å¿…é ˆ)
        image_rgb = image_pil.convert('RGB')
        # 2. ä½¿ç”¨ 'JPEG' æ ¼å¼
        # 3. è¨­å®š quality=90ï¼Œåœ¨å“è³ªå’Œæª”æ¡ˆå¤§å°é–“å–å¾—å¹³è¡¡
        image_rgb.save(byte_arr, format='JPEG', quality=90)
        
        encoded_string = base64.b64encode(byte_arr.getvalue()).decode('utf-8')
        
        # ï¼ï¼ï¼æ–°å¢æª¢æŸ¥ï¼ï¼ï¼
        if len(encoded_string) * 0.75 > 5 * 1024 * 1024: # ä¼°ç®— Base64 è§£ç¢¼å¾Œçš„å¤§å°
             # å¦‚æœé‚„æ˜¯å¤ªå¤§ï¼Œå°±ç”¨æ›´ä½çš„å“è³ªé‡è©¦
             byte_arr = io.BytesIO()
             image_rgb.save(byte_arr, format='JPEG', quality=75) # 75%
             encoded_string = base64.b64encode(byte_arr.getvalue()).decode('utf-8')
             
        return encoded_string

    def _generate_v2_prompt(self, 
                            query_case_id: str,
                            density_rag_reports: List[Dict[str, Any]],
                            lesion_rag_reports: List[Dict[str, Any]],
                            detected_lesions_count: int
                            ) -> str:
        """
        [V2 ç‰ˆ]
        å»ºæ§‹å¤šéšæ®µ RAG çš„ System Prompt
        """
        newline = '\n'
        
        # --- å¯†åº¦ RAG éƒ¨åˆ† ---
        density_prompt = "--- å¯†åº¦/é¢¨æ ¼åƒè€ƒ (Density/Style References) ---\n"
        density_prompt += "æŒ‡ç¤º: åƒ…ä½¿ç”¨æ­¤è™•çš„å ±å‘Šä¾†æ±ºå®šã€Œä¹³æˆ¿å¯†åº¦ã€çš„æªè¾­å’Œæ•´ä»½å ±å‘Šçš„ã€Œæ ¼å¼ã€ã€‚\n"
        for i, rag_result in enumerate(density_rag_reports, 1):
            case_id = rag_result['case_id']
            report = self.reports_dict.get(case_id)
            if report:
                # æå–å¯†åº¦å’Œ BI-RADS (å¦‚æœæœ‰çš„è©±)
                density_match = re.search(r'1\..+\.', report.raw_text)
                birads_match = re.search(r'BI-RADS Category[^\.]+\.', report.raw_text)
                density = density_match.group(0) if density_match else "[å¯†åº¦æè¿°]"
                birads = birads_match.group(0) if birads_match else "[BI-RADS çµè«–]"
                density_prompt += f"- é¢¨æ ¼ {i} ({case_id}): {density.strip()} ... {birads.strip()}\n"
            
        # --- ç—…ç¶ RAG éƒ¨åˆ† ---
        lesion_prompt = "--- ç—…ç¶åˆ†æåƒè€ƒ (Lesion Analysis References) ---\n"
        if detected_lesions_count > 0:
            lesion_prompt += f"æŒ‡ç¤º: æˆ‘çš„æª¢æ¸¬å™¨åœ¨å½±åƒä¸­æ‰¾åˆ°äº† {detected_lesions_count} å€‹å¯ç–‘ç—…ç¶ (é¡¯ç¤ºåœ¨ä¸‹é¢)ã€‚\n"
            lesion_prompt += "è«‹ä½¿ç”¨ä»¥ä¸‹ã€Œç›¸ä¼¼ç—…ç¶ã€çš„å ±å‘Šï¼Œä¾†å¹«åŠ©ä½ æè¿°é€™äº›æ–°ç™¼ç¾çš„ç—…ç¶ (ä¾‹å¦‚å¤§å°ã€å½¢ç‹€ã€é‚Šç·£)ã€‚\n"
            
            for i, rag_result in enumerate(lesion_rag_reports, 1):
                case_id = rag_result['case_id']
                view = rag_result['view']
                report = self.reports_dict.get(case_id)
                if report:
                    # æˆ‘å€‘åªé¡¯ç¤ºå ±å‘Šçš„ã€ŒFindingsã€éƒ¨åˆ†
                    findings_match = re.search(r'(Bilateral screening mammograms.+?)(?=BI-RADS|$)', report.raw_text, re.DOTALL)
                    findings = findings_match.group(1).strip() if findings_match else report.raw_text
                    # ç°¡åŒ–ï¼Œåªå– 150 å­—å…ƒ
                    findings_snippet = findings.replace(newline, ' ').strip()[:150]
                    lesion_prompt += f"- ç—…ç¶ {i} (ä¾†è‡ª {case_id}, {view}, ç›¸ä¼¼åº¦ {rag_result['similarity']:.3f}): \"...{findings_snippet}...\"\n"
        else:
            lesion_prompt += "æŒ‡ç¤º: æˆ‘çš„æª¢æ¸¬å™¨åœ¨å½±åƒä¸­**æ²’æœ‰**æ‰¾åˆ°æ˜é¡¯çš„ç—…ç¶ã€‚\n"
            lesion_prompt += "è«‹ç¢ºèªå½±åƒï¼Œå¦‚æœç¢ºå¯¦æ²’æœ‰ç—…ç¶ï¼Œè«‹åƒè€ƒã€Œå¯†åº¦ RAGã€å ±å‘Šä¾†æ’°å¯«ä¸€ä»½é™°æ€§ (BI-RADS 1) å ±å‘Šã€‚\n"
        

        # --- æœ€çµ‚çµ„åˆ Prompt ---
        final_prompt = f"""You are an expert radiologist. Your task is to analyze the provided mammography images for patient {query_case_id} and generate a professional report.

**CRITICAL INSTRUCTIONS:**
1.  **IMAGE FIRST:** Your primary source of truth is the provided images. **Trust the images over the text references.**
2.  **DETECTED LESIONS:** I am providing you with **Full-View Images** (RCC, LCC, RMLO, LMLO) and **Cropped Lesion Images** (if any were detected). You MUST describe the findings in the Cropped Lesion Images.
3.  **USE RAG CONTEXT:**
    * Use the **Lesion Analysis References** to help *describe* the detected lesions.
    * Use the **Density/Style References** to help describe the *breast density* and *report format*.
4.  **TASK:** Synthesize ALL information into the mandatory format. If you see a lesion (even if RAG context is negative), report it (BI-RADS 0). If you see NO lesions (even if RAG context mentions one), report it as negative (BI-RADS 1).

{density_prompt}
{lesion_prompt}
---
**MANDATORY FORMAT (Fill this based on YOUR analysis of the images):**

<REPORT_TEXT>
**Bilateral screening mammograms**

1. [Your description of breast density based on Full-View Images]
2. [Your description of additional findings (if any)]
3. [Your description of key findings based on Cropped Lesion Images, e.g., location, size, margins]
</REPORT_TEXT>

<BI_RADS_CATEGORY>
[Your category (0, 1, 2...) based on ALL images. **MUST BE A SINGLE DIGIT**]
</BI_RADS_CATEGORY>

<COMPARISON>
[State 'Not specified/Unknown' unless comparison info is provided]
</COMPARISON>
"""
        return final_prompt

    def run_v2_evaluation(self, query_case_id: str, k_density: int = 3, k_lesion: int = 3):
        """
        [V2 ç‰ˆ]
        åŸ·è¡Œå®Œæ•´çš„ã€Œæª¢æ¸¬ -> é›™ RAG -> å¤šæ¨¡æ…‹ç”Ÿæˆã€æµç¨‹
        """
        print(f"\n{'='*80}")
        print(f"ğŸš€ é–‹å§‹ V2 è©•ä¼°: {query_case_id}")
        print("="*80)
        
        # 1. å–å¾—çœŸå¯¦å ±å‘Š (ç”¨æ–¼æœ€å¾Œæ¯”è¼ƒ)
        ground_truth_report = self.reports_dict.get(query_case_id)
        if not ground_truth_report:
            print(f"âŒ æ‰¾ä¸åˆ° {query_case_id} çš„çœŸå¯¦å ±å‘Šï¼Œä¸­æ­¢è©•ä¼°")
            return
            
        # 2. æå–æŸ¥è©¢æ¡ˆä¾‹çš„ç‰¹å¾µ (å‘¼å« V3 API æª¢æ¸¬å™¨)
        print(f"ğŸ”„ (Step 1/5) æå– {query_case_id} çš„å³æ™‚ç‰¹å¾µ (å‘¼å« Roboflow API)...")
        # æˆ‘å€‘éœ€è¦åŸå§‹æ¡ˆä¾‹çš„ç›®éŒ„
        case_data_v2 = self.retrieval_system.features_dict_v2.get(query_case_id)
        if not case_data_v2:
            print(f"âŒ æ‰¾ä¸åˆ° {query_case_id} çš„ V2 ç‰¹å¾µ (ç„¡æ³•å®šä½å½±åƒ)ï¼Œä¸­æ­¢è©•ä¼°")
            return
            
        source_dir = case_data_v2['source_dir']
        case_dir_path = os.path.join('preprocessed_images', source_dir, query_case_id)
        
        # å‘¼å«ç‰¹å¾µæå–å™¨
        try:
            live_features = self.feature_extractor.extract_case_features(case_dir_path)
            total_lesions = sum(len(v.get('lesions', [])) for k, v in live_features.items() if k in ['RCC', 'LCC', 'RMLO', 'LMLO'])
            print(f"âœ… (Step 1/5) ç‰¹å¾µæå–å®Œæˆã€‚æª¢æ¸¬åˆ° {total_lesions} å€‹ç—…ç¶ã€‚")
        except Exception as e:
            print(f"âŒ (Step 1/5) å³æ™‚ç‰¹å¾µæå–å¤±æ•—: {e}")
            return

        # 3. åŸ·è¡Œã€Œå¯†åº¦ RAGã€
        print(f"ğŸ”„ (Step 2/5) åŸ·è¡Œã€Œå¯†åº¦ RAGã€...")
        density_rag_reports = self.retrieval_system.search_global(
            query_feature=live_features['avg_all_global'],
            k=k_density,
            feature_type='avg_all_global'
        )
        print(f"âœ… (Step 2/5) æ‰¾åˆ° {len(density_rag_reports)} å€‹å¯†åº¦ç›¸ä¼¼æ¡ˆä¾‹")

        # 4. åŸ·è¡Œã€Œç—…ç¶ RAGã€
        print(f"ğŸ”„ (Step 3/5) åŸ·è¡Œã€Œç—…ç¶ RAGã€...")
        all_lesion_rag_reports = []
        # éæ­·æ‰€æœ‰æª¢æ¸¬åˆ°çš„ç—…ç¶
        for view in ['RCC', 'LCC', 'RMLO', 'LMLO']:
            if view in live_features:
                for lesion in live_features[view]['lesions']:
                    print(f"  - æª¢ç´¢ {view} ä¸Šçš„ç—…ç¶ (Conf: {lesion['conf']:.2f})...")
                    lesion_rag_results = self.retrieval_system.search_lesion(
                        query_roi_feature=lesion['roi_feature'],
                        k=k_lesion
                    )
                    all_lesion_rag_reports.extend(lesion_rag_results)
        
        # å»é™¤é‡è¤‡çš„ (å¯èƒ½å¤šå€‹ç—…ç¶æª¢ç´¢åˆ°åŒä¸€å€‹æ¡ˆä¾‹)
        seen_case_ids = set()
        unique_lesion_rag_reports = []
        for report in all_lesion_rag_reports:
            if report['case_id'] not in seen_case_ids:
                unique_lesion_rag_reports.append(report)
                seen_case_ids.add(report['case_id'])
        print(f"âœ… (Step 3/5) æ‰¾åˆ° {len(unique_lesion_rag_reports)} å€‹ç¨ç‰¹çš„ç›¸ä¼¼ç—…ç¶æ¡ˆä¾‹")
        
        # 5. æº–å‚™å½±åƒ (å…¨å¹… + ç—…ç¶è£å‰ª)
        print(f"ğŸ”„ (Step 4/5) æº–å‚™å¤šæ¨¡æ…‹å½±åƒ (å…¨å¹… + è£å‰ª)...")
        content_list = []
        
        # è®€å– 4 å¼µå…¨å¹… PIL å½±åƒ
        full_pil_images = self.retrieval_system.get_case_images_from_v2_features(query_case_id)
        
        # a. åŠ å…¥å…¨å¹…å½±åƒ
        for view, pil_img in full_pil_images.items():
            content_list.append({"type": "text", "text": f"--- Full-View Image: {view} ---"})
            content_list.append({
                "type": "image",
                "source": {"type": "base64", "media_type": "image/jpeg", "data": self._image_to_base64(pil_img)} # <-- ä¿®æ­£ A
            })
            
        # b. åŠ å…¥è£å‰ªçš„ç—…ç¶å½±åƒ
        detected_lesions_count = 0
        for view in ['RCC', 'LCC', 'RMLO', 'LMLO']:
            if view in live_features and view in full_pil_images:
                pil_img = full_pil_images[view] # å–å¾—å°æ‡‰çš„å…¨å¹…å½±åƒ
                for lesion in live_features[view]['lesions']:
                    detected_lesions_count += 1
                    bbox = lesion['bbox']
                    # è£å‰ª (left, upper, right, lower)
                    cropped_pil = pil_img.crop((bbox[0], bbox[1], bbox[2], bbox[3]))
                    loc_desc = ""
                    if 'rel_center' in lesion:
                        rx, ry = lesion['rel_center']
                        # ç°¡å–®çš„ä½ç½®æ–‡å­—æè¿°
                        h_pos = "Left" if rx < 0.33 else ("Right" if rx > 0.66 else "Center")
                        v_pos = "Top" if ry < 0.33 else ("Bottom" if ry > 0.66 else "Middle")
                        loc_desc = f"(Location in full image: {v_pos}-{h_pos}, x={rx:.2f}, y={ry:.2f})"

                    # å°‡ä½ç½®æè¿°åŠ åˆ° Prompt ä¸­
                    content_list.append({
                        "type": "text",
                        "text": f"--- Cropped Lesion #{detected_lesions_count} (from {view} view, Conf: {lesion['conf']:.2f}) {loc_desc} ---"
                    })
                    content_list.append({
                        "type": "image",
                        "source": {"type": "base64", "media_type": "image/jpeg", "data": self._image_to_base64(cropped_pil)} # <-- ä¿®æ­£ B
                    })
        print(f"âœ… (Step 4/5) å½±åƒæº–å‚™å®Œæˆ (4 å¼µå…¨å¹…, {detected_lesions_count} å¼µç—…ç¶è£å‰ª)")

        # 6. å»ºæ§‹ Prompt
        system_prompt = self._generate_v2_prompt(
            query_case_id=query_case_id,
            density_rag_reports=density_rag_reports,
            lesion_rag_reports=unique_lesion_rag_reports,
            detected_lesions_count=detected_lesions_count
        )
        
        # 7. å‘¼å« Claude API
        print(f"ğŸ”„ (Step 5/5) å‘¼å« Claude API (æ¨¡å‹: claude-sonnet-4-5-20250929)...")
        
        # åŠ å…¥æœ€å¾Œçš„è§¸ç™¼è©
        content_list.append({
            "type": "text",
            "text": "Please analyze all provided images and generate the mammography report based on my system instructions."
        })
        
        try:
            message = self.client.messages.create(
       
                model="claude-sonnet-4-5-20250929", 
                max_tokens=2048,
                temperature=0.1, # é†«ç™‚å ±å‘Šéœ€è¦ä½æº«ã€é«˜ç¢ºå®šæ€§
                system=system_prompt,
                messages=[
                    {
                        "role": "user",
                        "content": content_list
                    }
                ]
            )
            generated_report = message.content[0].text
            print("âœ… (Step 5/5) å ±å‘Šç”Ÿæˆå®Œæˆï¼")
            
            # --- æœ€çµ‚çµæœé¡¯ç¤º ---
            print("\n" + "="*80)
            print(f"ğŸ”¬ V2 RAG è©•ä¼°çµæœ: {query_case_id}")
            print("="*80)
            
            print(f"\nğŸ“‹ çœŸå¯¦å ±å‘Š (Ground Truth):")
            print("-" * 80)
            print(ground_truth_report.raw_text)
            
            print(f"\nğŸ¤– V2 ç”Ÿæˆå ±å‘Š (AI Generated):")
            print("-" * 80)
            print(generated_report)
            
            print(f"\nğŸ“Š RAG æª¢ç´¢è³‡è¨Š:")
            print("-" * 80)
            print(f"  æª¢æ¸¬åˆ°çš„ç—…ç¶æ•¸: {detected_lesions_count}")
            print("\n  --- å¯†åº¦ RAG (Top 1) ---")
            if density_rag_reports:
                print(f"  - {density_rag_reports[0]['case_id']} (Sim: {density_rag_reports[0]['similarity']:.3f})")
            
            print("\n  --- ç—…ç¶ RAG (Top 1) ---")
            if unique_lesion_rag_reports:
                r = unique_lesion_rag_reports[0]
                print(f"  - {r['case_id']} / {r['view']} (Sim: {r['similarity']:.3f})")

            print(f"\nğŸ’° API ä½¿ç”¨:")
            print("-" * 80)
            print(f"  Input tokens: {message.usage.input_tokens}")
            print(f"  Output tokens: {message.usage.output_tokens}")
            print("="*80)
            
            return generated_report

        except Exception as e:
            print(f"âŒ (Step 5/5) API å‘¼å«å¤±æ•—: {e}")
            raise

# ==================== åŸ·è¡Œ V2 è©•ä¼° ====================
if __name__ == "__main__":
    
    # ï¼ï¼ï¼æ³¨æ„ï¼ï¼ï¼
    # åŸ·è¡Œå‰ï¼Œè«‹ç¢ºä¿ä½ å·²ç¶“è¨­å®šäº†ç’°å¢ƒè®Šæ•¸
    # export ANTHROPIC_API_KEY="..."
    # export ROBOFLOW_API_KEY="..."
    
    # 1. åˆå§‹åŒ– V2 RAG ç³»çµ±
    try:
        rag_system_v2 = MammographyRAGSystemV2(
            reports_dir='Kang_Ning_General_Hospital/'
        )
        
        # 2. æ¸¬è©¦é‚£å€‹å¤±æ•—çš„æ¡ˆä¾‹ï¼
        test_case_id = "MAMO_DEID_20230721_-00009"
        
        # 3. åŸ·è¡Œ V2 è©•ä¼°
        rag_system_v2.run_v2_evaluation(
            query_case_id=test_case_id,
            k_density=3,
            k_lesion=3
        )
        
        # 4. (å¯é¸) æ¸¬è©¦å¦ä¸€å€‹æ¡ˆä¾‹ï¼Œä¾‹å¦‚ä½ ç¬¬ä¸€å€‹æˆåŠŸçš„
        # test_case_id_2 = "MAMO_DEID_20230721_-00010"
        # rag_system_v2.run_v2_evaluation(
        #     query_case_id=test_case_id_2,
        #     k_density=3,
        #     k_lesion=3
        # )

    except ValueError as e:
        print(f"\nâŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        print("è«‹æª¢æŸ¥ä½ çš„ç’°å¢ƒè®Šæ•¸è¨­å®šã€‚")
    except ImportError as e:
        print(f"\nâŒ åŒ¯å…¥éŒ¯èª¤: {e}")
        print("è«‹ç¢ºä¿ 'Get_Report.py' å’Œ 'detection_and_feature_extractor.py' æª”æ¡ˆåœ¨åŒä¸€å€‹è³‡æ–™å¤¾ä¸­")