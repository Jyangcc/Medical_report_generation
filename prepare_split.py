import os
import pickle
import json
import random

FEATURES_V2_FILE = 'mammography_features_v2.pkl'
TEST_SET_RATIO = 0.2 # 20% çš„è³‡æ–™ä½œç‚ºæ¸¬è©¦é›†

def split_dataset():
    print(f"ğŸ”„ è¼‰å…¥ V2 ç‰¹å¾µæª”æ¡ˆ: {FEATURES_V2_FILE} ä»¥å–å¾—æ‰€æœ‰ case ID...")
    
    if not os.path.exists(FEATURES_V2_FILE):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ° {FEATURES_V2_FILE}")
        print("è«‹å…ˆåŸ·è¡Œ 'run_extraction.py' ä¾†ç”Ÿæˆé€™å€‹æª”æ¡ˆã€‚")
        return

    with open(FEATURES_V2_FILE, 'rb') as f:
        features_dict = pickle.load(f)
        
    all_case_ids = list(features_dict.keys())
    
    # éš¨æ©Ÿæ‰“äº‚
    random.seed(42) # ä½¿ç”¨å›ºå®šçš„ seed ç¢ºä¿æ¯æ¬¡åˆ‡åˆ†éƒ½ä¸€æ¨£
    random.shuffle(all_case_ids)
    
    # è¨ˆç®—åˆ‡åˆ†é»
    total_cases = len(all_case_ids)
    test_size = int(total_cases * TEST_SET_RATIO)
    train_size = total_cases - test_size
    
    # åˆ‡åˆ†
    train_ids = all_case_ids[:train_size]
    test_ids = all_case_ids[train_size:]
    
    print(f"âœ… è³‡æ–™åˆ‡åˆ†å®Œæˆ:")
    print(f"  - ç¸½æ¡ˆä¾‹æ•¸: {total_cases}")
    print(f"  - è¨“ç·´é›† (80%): {len(train_ids)} å€‹æ¡ˆä¾‹")
    print(f"  - æ¸¬è©¦é›† (20%): {len(test_ids)} å€‹æ¡ˆä¾‹")
    
    # å„²å­˜åˆ° JSON
    with open('train_cases.json', 'w') as f:
        json.dump(train_ids, f, indent=2)
    print(f"ğŸ’¾ è¨“ç·´é›† ID å·²å„²å­˜åˆ°: train_cases.json")
    
    with open('test_cases.json', 'w') as f:
        json.dump(test_ids, f, indent=2)
    print(f"ğŸ’¾ æ¸¬è©¦é›† ID å·²å„²å­˜åˆ°: test_cases.json")

if __name__ == "__main__":
    split_dataset()